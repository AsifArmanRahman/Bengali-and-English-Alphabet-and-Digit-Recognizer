{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "local-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "data_dir = os.path.join('data/Bengali','digit')\n",
    "\n",
    "paths_train_a = glob.glob(os.path.join(data_dir, 'training-a', '*.png'))\n",
    "paths_train_b = glob.glob(os.path.join(data_dir, 'training-b', '*.png'))\n",
    "paths_train_e = glob.glob(os.path.join(data_dir, 'training-e', '*.png'))\n",
    "paths_train_c = glob.glob(os.path.join(data_dir, 'training-c', '*.png'))\n",
    "paths_train_d = glob.glob(os.path.join(data_dir, 'training-d', '*.png'))\n",
    "paths_train_all = paths_train_a + paths_train_b + paths_train_c + paths_train_d + paths_train_e\n",
    "\n",
    "paths_test_a = glob.glob(os.path.join(data_dir, 'testing-a', '*.png'))\n",
    "paths_test_b = glob.glob(os.path.join(data_dir, 'testing-b', '*.png'))\n",
    "paths_test_e = glob.glob(os.path.join(data_dir, 'testing-e', '*.png'))\n",
    "paths_test_c = glob.glob(os.path.join(data_dir, 'testing-c', '*.png'))\n",
    "paths_test_d = glob.glob(os.path.join(data_dir, 'testing-d', '*.png'))\n",
    "paths_test_f = glob.glob(os.path.join(data_dir, 'testing-f', '*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\n",
    "paths_test_auga = glob.glob(os.path.join(data_dir, 'testing-auga', '*.png'))\n",
    "paths_test_augc = glob.glob(os.path.join(data_dir, 'testing-augc', '*.png'))\n",
    "paths_test_all = paths_test_a + paths_test_b + paths_test_c + paths_test_d + paths_test_e + paths_test_f + paths_test_auga + paths_test_augc\n",
    "\n",
    "path_label_train_a = os.path.join(data_dir, 'training-a.csv')\n",
    "path_label_train_b = os.path.join(data_dir, 'training-b.csv')\n",
    "path_label_train_e = os.path.join(data_dir, 'training-e.csv')\n",
    "path_label_train_c = os.path.join(data_dir, 'training-c.csv')\n",
    "path_label_train_d = os.path.join(data_dir, 'training-d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afraid-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def get_key(path):\n",
    "\n",
    "    key = path.split(sep=os.sep)[-1]\n",
    "    \n",
    "    return key\n",
    "\n",
    "\n",
    "def get_data(paths_img,path_label=None,resize_dim=None):\n",
    "\n",
    "    X = []\n",
    "    \n",
    "    for i, path in enumerate(paths_img):\n",
    "\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if resize_dim is not None:\n",
    "            \n",
    "            img = cv2.resize(img, (resize_dim, resize_dim), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        gaussian_3 = cv2.GaussianBlur(img, (9, 9), 10.0) \n",
    "        img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "        \n",
    "        X.append(img) \n",
    "        \n",
    "        if i == len(paths_img) - 1:\n",
    "            \n",
    "            end = '\\n'\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            end = '\\r'\n",
    "        \n",
    "        print('processed {}/{}'.format(i+1, len(paths_img)), end = end)\n",
    "        \n",
    "    X = np.array(X) \n",
    "    \n",
    "    if  path_label is None:\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        df = pd.read_csv(path_label) \n",
    "        df = df.set_index('filename') \n",
    "\n",
    "        y_label = [df.loc[get_key(path)]['digit'] for path in  paths_img] \n",
    "        y = to_categorical(y_label, 10)\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 19702/19702\n",
      "processed 359/359\n",
      "processed 24298/24298\n",
      "processed 10908/10908\n",
      "processed 16778/16778\n"
     ]
    }
   ],
   "source": [
    "RESIZE_DIM = 28\n",
    "\n",
    "X_train_a, y_train_a = get_data(paths_train_a, path_label_train_a, resize_dim =RESIZE_DIM)\n",
    "X_train_b, y_train_b = get_data(paths_train_b, path_label_train_b, resize_dim =RESIZE_DIM)\n",
    "X_train_c, y_train_c = get_data(paths_train_c, path_label_train_c, resize_dim =RESIZE_DIM)\n",
    "X_train_d, y_train_d = get_data(paths_train_d, path_label_train_d, resize_dim =RESIZE_DIM)\n",
    "X_train_e, y_train_e = get_data(paths_train_e, path_label_train_e, resize_dim =RESIZE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mighty-lancaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72045, 28, 28), (72045, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all = np.concatenate((X_train_a, X_train_b, X_train_c, X_train_d, X_train_e), axis=0)\n",
    "y_train_all = np.concatenate((y_train_a, y_train_b, y_train_c, y_train_d, y_train_e), axis=0)\n",
    "\n",
    "X_train_all.shape, y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "numtaY_label = np.argmax(y_train_all, axis=1) \n",
    "\n",
    "# get the list of tuples\n",
    "list_of_tuples = list(zip(numtaY_label)) \n",
    "\n",
    "# Converting lists of tuples into pandas Dataframe. \n",
    "data = pd.DataFrame(list_of_tuples, columns = ['label']) \n",
    "data = data.sort_values(by=['label'])\n",
    "\n",
    "\n",
    "# Change label to alphabets\n",
    "digit_mapper = {0: '০', 1: '১', 2: '২', 3: '৩', 4: '৪', 5: '৫', 6: '৬', 7: '৭', 8: '৮', 9: '৯'}\n",
    "\n",
    "data['label'] = data['label'].map(digit_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d784f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEGCAYAAACEgjUUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATWElEQVR4nO3dfbReZXnn8e+PhBcTSAQBxWBMTUUQhLEe6hQQRFHUopa2iM6MOrbTVFGYDmKtC0XEl6Wlah07WrKchYNaQFSoWBeOlaJWB/FA24UICGihLECgjSG8SajX/LF3yEk4IQlm72eH/f2sddZ5zn72ea4rh8Mvd+69n/tOVSFJemzbZtINSJK6Z9hL0ggY9pI0Aoa9JI2AYS9JIzB30g3MZtddd60lS5ZMug1J2qpcfvnld1bVbrM9N8iwX7JkCdPT05NuQ5K2Kklu3NBzgwz7q2/+V57ztrMm3YYk9ery01/X2Ws7Zy9JI2DYS9IIGPaSNAKGvSSNgGEvSSNg2EvSCBj2kjQCnYd9kp2T/GWS25Lcn+TLSZ7SdV1J0lp9jOw/D7wWOAVYApwBfDHJOm/oSrIsyXSS6QfvXdVDW5I0Hp2GfZIDgCOAZVW1vKpuq6q/Ae4EXjbz3Pb5qaqamjtvpy7bkqTR6Xpk/zTgzqr63HrHnwDs1XFtSVKr67C/Erhj5oEkzwWeA/y449qSpFanYV9V1wOXJ3l9kl2SHANcCFwNfKXL2pKktfq4QPtG4GDgn4HlwMXAi6vqgR5qS5LoYYnjqroHWNZ+SJImwDdVSdIIGPaSNAKD3Klqnz2fwHSHO7ZI0tg4spekETDsJWkEDHtJGoFBztk/cOtV3HTasybdhiT1YvEpV3Zew5G9JI2AYS9JI2DYS9IIGPaSNAKGvSSNQB970O6W5F+SnNh1LUnS7PoY2S8AFgHP66GWJGkWnYd9Vd0AnAr8VpI/7rqeJOnhenlTVVWdlmQu8KEkN1fVX61/TpKH1rxftHDbPtqSpNHo7QJtVZ0C/DFwRpJFszy/vKqmqmpql/lz+mpLkkah17txqup04LPAm/usK0ljN4lbLz8J/NoE6krSaPVx6+U2Sc5I8m9Jvgq8HPhJ13UlSWv1cYH2ENZuNv5S4LnAVA91JUmtPqZx/gH4BnA3cBFwcFU5spekHnU+sq+qVcARXdeRJG2Ya+NI0ggMcqeq7fbYl8WnTE+6DUl6zHBkL0kjYNhL0ggY9pI0AoOcs7/m9ms4+OMHT7oNSerNd47/Tqev78hekkbAsJekETDsJWkEDHtJGgHDXpJGoI8ljh+X5Lokp3ddS5I0uz5G9r+gWfHyrUnOTPL4HmpKkmboPOyr6ufAf6TZf/aVwKVJFnRdV5K0Vi9z9lX186r6M2ApcD3w9vXPSbIsyXSS6dV3r+6jLUkajU7DPsnuSeas+bqqVgD/FThg/XOranlVTVXV1LY7bttlW5I0On2M7K9I8vtJnpxkR5otCq/ooa4kqdXp2jhVdXuSnwOfmnH4IuBVXdaVJK2rj5H9ScDnae7I+S5wbLtVoSSpJ33cjfOtqjoWWAxcAvxdkr27ritJWqu3d9BW1YqqOplmCudjSQ7tq7YkjV3vyyVU1Q3AUcDrkizuu74kjdFENi+pqtVJ/gB4/GzP77373p0v5C9JYzKxnaqqqoAVk6ovSWPiqpeSNAKGvSSNgGEvSSMwsTn7R7Lq2mv55qGHTboNSerNYd/6Zqev78hekkbAsJekETDsJWkEDHtJGgHDXpJGoJe7cdo1cI4G7gXOrqq7+6grSWp0FvZJnl5V1yXZCZgGdgN+AZyY5NCquqOr2pKkdXU5jfPOJNsD+9AEPcBXgPOB961/8swNx1eudsNxSdqSugz7y4BfB66j2aUK4FbgZOC5SdapPXPD8YXbuuG4JG1JXYb9hcAbqmoFcDhwAvDWdrXLHwG7dFhbkjRDZ3P2VXVTknlJDqqq79LM29OO6BdV1Z1d1ZYkravrWy/fBpyZ5OgkuyXZH/gr4KKO60qSZug07KvqX4CXAm8EbgK+DvwA+ECXdSVJ6+r8Pvuq+jFwZNd1JEkb5jtoJWkEDHtJGoFBbl6y0zOe0flC/pI0Jo7sJWkEDHtJGgHDXpJGYJBz9rffvJK/eOuFk25Dknr1lg+/vLPXdmQvSSNg2EvSCBj2kjQChr0kjYBhL0kj0EvYt8sbfyrJV5L8KMlfJJnTR21JUn8j+3OA86vqKGB/YG/guJ5qS9LodR72SRYCLwCuBKiq+2nWtX9a17UlSY0+RvYPAPcBH0myOMnvAG8Bls88KcmyJNNJpu++d2UPbUnSeHQe9lV1H/CHNJuO/xA4DzgXuGa985ZX1VRVTe04b2HXbUnSqPQ1Z7+UZupmD2Av4BXAaT3VlqTR62PO/gjgncDxVbWqqq4H3gcc3XVtSVLjUYd9kmdt4qkrgXuAZyZ5fJL9gdcBNz/a2pKkzbPBVS+TBLiUJqgfOgxU+/kpwK9urEBVfT/J64GPAs8EVgDfAE589G1LkjbHBsO+qirJsqr6p9me34yRPVV1AXDBZncnSdoiHnEaZ2bQJ3l6kk8m+aP23nnfAStJW4nNmbP/APDnwI5VtRJ4UycdSZK2uM3ZqerGqro2yQNJdgCe01VTu++5sNMdWyRpbDYn7M9Mcg5wJPBa4PRuWpIkbWmbHPZVdRXw6iRPBO6sqn/vri1J0pa0yWGf5PeANwA/An6c5H9X1W2ddSZJ2mJSVZt2YvL/gOdX1c/br99XVe/soqlFT9i5jnvpC7t4aUkarJM/+4Vf6vuTXF5VU7M9tzl343wRmLlC2UG/VFeSpN5s7B20XwEet+YQcEKS64HtgX/svDtJ0haxsXfQfrCqvj3b80kWdNeWJGlLesQLtDODPslLgEOAXYFbgAMBb4aXpK3A5szZHw9cQjOFcw3wrU39xiTPTvKlJGe1Sy1Iknq0OWH/d8C3gatodpvad1O+KcnvA5cBRwFz26UWJEk92pyw/zLN1oIXto+zsW9IcihwBvBJmk3HD0vym0m2exS9SpIepY3djXMhMG/NofbzmvXs99qE1/8Y8MWqOqF9zdNp7vC5JsmLqsoNTCSpBxu7G+fPq+pvZ3s+ySGP9MJJ9gX2B45pv34OzXaEnwDeUVV3rXf+MmAZwMJ5j0OStOVsbD37WYO+fe7vN/La+wE/bvecBfhfwEeq6s3rB337esuraqqqpubvsP3G+pYkbYbNWfVyc90H3A0P3ZP/LOCwDutJkjbgUW84vgm+CSxOsoRmV6v716yrI0nqV2dh395i+UbgS8Bi4LIkL+2qniRpw7oc2VNV5wH/GfgTYDfg7CSv6bKmJOnhupyzB6CqrgYMeEmaoE5H9pKkYeh8ZP9o7PErS3/pRfwlSWs5spekETDsJWkEDHtJGgHDXpJGYJAXaO+/dRVXv//iSbchSb3Y5+QXdF7Dkb0kjYBhL0kjYNhL0ggY9pI0Ap2HfZLvJfl013UkSRvWx8j+ZuA/tXvaSpImoLOwT/Jf2ocn0dziuU17fCrJ/K7qSpIersuR/aIkC2lG9vdV1b8n2YZmw/H/02FdSdJ6ugz77wBHV9Vq4Jok+wEfBw4Anphk0cyTkyxLMp1k+t/u+VmHbUnS+HS5LeHfAy9LMgd4G3Ax8NvA64FzgD3XO395VU1V1dQu8x/fVVuSNEpdX6A9Hzi5qi6uqt2rao+qOgfYD7ix49qSpFbXe9CeDeyT5CNJnprkCUneBOxeVbd1WVuStFYft16+FrgH+B5wC3Ak8Ic91JUktfrYcPxB4F3thyRpAlwuQZJGwLCXpBEY5OYlO+yxUy+L+UvSWDiyl6QRMOwlaQQMe0kaAcNekkZgkBdob7nlFk499dRJtyFJnesr6xzZS9IIGPaSNAKGvSSNgGEvSSPQedgn2TXJ+UlWJbkyySFd15QkrauPu3E+A+wFvAh4EnBekqVVdW8PtSVJdDyyT7IAeAnwhqq6tKouAH4AvLDLupKkdXU9jXMfsBK4I8ncJHOB7wN7r3/izA3H773XQb8kbUldb0u4GngdcAmwuv14B7BwlnMf2nB83rx5XbYlSaPT+QXaqvpyVT0R2Lb9+FMG+s5dSXqs6u3Wy6p6sN2icKe+akqSGpO4z34OsHcS52okqSeTCPurgVcCh0+gtiSN0iTmzj8B3ApcPIHakjRKvYd9VT0AnNt3XUkaM9fGkaQRSFVNuoeHmZqaqunp6Um3IUlblSSXV9XUbM85spekETDsJWkEDHtJGoFBLluwYsXVfP68X590G5LUqVcdc1lvtRzZS9IIGPaSNAKGvSSNgGEvSSNg2EvSCHQW9klOSnKVSxlL0uR1ObK/DVgEHNRhDUnSJugs7Kvqs8AFwC7rP5dkhySHdlVbkrSuPubsD09ye5Irk/xKkiuB+4AXzzwpybIk00mm77rrwR7akqTx6OMdtPOAA4D9gX8E3gL8BPjuzJOqajmwHGDp0vnDW4pTkrZifYT9mVV1a3uhdgFwRVVd1UNdSVKrz1svTwR+AazosaYkie7D/mfAnkneDhwHfKiqbum4piRpPV1P47wf+CqwJ3BSVX2443qSpFl0GvZVdQdwYJc1JEkb53IJkjQChr0kjcAgd6raeed9et3BRZIe6xzZS9IIGPaSNAKGvSSNwCDn7H+44i4O+MLXJt2GJHXin373yN5rOrKXpBEw7CVpBDoP+yT+hSJJE9ZpECeZA9yU5IQu60iSHlnXo+4dgSe1nyVJE9Jp2FfVSuADwGlJzkqyb5f1JEmz63w+vapOAV4LPB+4Msl5SXbvuq4kaa1eLp5W1dnAXsCbgcOAbyeZ30dtSVI/d+MckeQ64BZgJ+DZwIM0O1fNPG9Zkukk0w/etbLrtiRpVLq+G2cn4HM00zjPA/47sBR4b/v1Q6pqeVVNVdXU3AULu2xLkkan6+USpoBVVXUpQJJzgd8A5gP3dVxbktTqOuzvBpYmuR34TWAecCzN6P7wjmtLklpdz9lPA+e1dX4K7AtcDxxcVVd0XFuS1Op6w/ECXjXj0PM2dK4kqTuuWyNJI2DYS9IIDHLzkmfuvIDpCSzuL0mPVY7sJWkEDHtJGoE0N8wMS5JVwLWT7mMz7ArcOekmNoP9dst+u2W/G/bUqtptticGOWcPXFtVU5NuYlMlmbbf7thvt+y3W0Pp12kcSRoBw16SRmCoYb980g1sJvvtlv12y367NYh+B3mBVpK0ZQ11ZC9J2oIMe0kaAcNekkZgcGGf5J1JLkrymkn3skaS7ZO8sn08P8knknw7yT7tsX2SfKbte1577JgkZyf5nxPo94QkH0zy8aH3m2TnJKe1/fzO0Pud0feBSd4+9H6TzEny9STnJPmjofe7Xu+Lt6Z+2z6G229VDeYDOIRmv9ptgUuBbQbQ05OAk4Cr2q9PBhYDvwqc1x77SyDAfwPeTLMj10fb5z4L7Ntjvy8CXtU+/t5W0O8LaDa12QX40tD7bWvOBc4CPj30ftvf32Uzvh50v23NvYH3AfsNvV/gFcD5wBeAS4B3D7XfoY3sXwL8Q1WtBq4Cnj7hfqiq26rqz4A72kMHVtVNVXU9sEeS7YBdqvkv9zWav7AOAm5oz19zrK9+v15Vn08yF7h1K+j3YuBq4DXAJ4feb+sPgDPbx0Pv9ynAv874etD9JtkBeA/w7qr6wdD7BW6oqqOr6neBy4FfG2q/Qwv73YH728c/pRntDc3CGY9X06x78UD79Zqeh/DneD1NeG4N/S6lGc09j4H3m+TJwPbAT9pDg+6XJuyPTXJmksMZfr9HtZ8/luRdDLzfqroKIMmewC3AghlPD6rfoYX9z2h+OADbAbdNrpUN2ibJmp/bCmAlD+/5Z7Mc602SRcB+VfU1toJ+q+q6qjqe5l92Q+/3GOAZwCnAgcCSgff7VeBY4DjgQwz/5/s04LKqegtwALD/wPtd4/eAzzHgn+/Qwv47wBHt4x2r6iePdPKEXAEclORxwI1VdQ+wfZIdgWcD/5dmrvz57fkHAH/bV3PtL9qpwLuTPH0r6He79nNo/ucYdL9V9bGqehNwGvB94IKB93t/Ne6jCZlB/3xppjfmtI9vBL418H7XTD0tqarbGPLPt68LGZt4sWMb4FzgM8ALJt1P29MC4E00f/suo7n4cgnNnO0e7TkvBL4BfASY2x57B82Fm+N67vcNNL9MnwYuo7lAN+R+X0bzl9OngCOH3m9bez7NvPL3h94vzQXw9wBnAL+9FfQ7p/1d+DDw1qH329Y+Hnh1+3iw/bpcgiT9EpIcC/x1Vd2/0ZMnyLCXpBEY2py9JKkDhr0kjYBhL0kjYNhL0ggY9pI0Aoa9tIUlOXHSPUjrM+ylTdC+w/dhjzfgFR23I222uZNuQBqCJP8DeDLwXOD9wIuB/WmWRbiB5m3u+yXZj+bdkQcm+RNgFc1CVi+jWS/nZuCpSd4LXFNVn+v7zyLNxrDX6LXvgLypqj7aLiL3rqp6Y5I9gC9V1W8kuROgqn6Q5J72Wy8FPgi8vH18UFW9J8mNVfWuSfxZpA1xGkdqllb+Yfv4yTQLhlFVtwL3buR7v1ZVd9AsZ7ux6R1pYgx7Cf6Ztaut3g4clmSbdgOYG9vjq5PMS7IL665ZPtt6I79Ism1n3UqPgmEvNdvGHZXkr2nm3s+lWZHwT4H3tudcRLP13KuBnyY5kGbHof+QZD7Nvw4OaB9PA2clOQJpIFwITZJGwJG9JI2AYS9JI2DYS9IIGPaSNAKGvSSNgGEvSSNg2EvSCPx/mukuotsR9AoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fe = fm.FontEntry(\n",
    "    fname='models\\data\\Bengali\\font',\n",
    "    name='kalpurush')\n",
    "\n",
    "fm.fontManager.ttflist.insert(0, fe) # or append is fine\n",
    "plt.rcParams['font.family'] = fe.name # = 'your custom ttf font name'\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "graph = sns.countplot(y=data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "choice-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3489/3489\n",
      "processed 69/69\n",
      "processed 4381/4381\n",
      "processed 1948/1948\n",
      "processed 2970/2970\n",
      "processed 495/495\n",
      "processed 2168/2168\n",
      "processed 2106/2106\n"
     ]
    }
   ],
   "source": [
    "X_test_a = get_data(paths_test_a, resize_dim = RESIZE_DIM)\n",
    "X_test_b = get_data(paths_test_b, resize_dim = RESIZE_DIM)\n",
    "X_test_c = get_data(paths_test_c, resize_dim = RESIZE_DIM)\n",
    "X_test_d = get_data(paths_test_d, resize_dim = RESIZE_DIM)\n",
    "X_test_e = get_data(paths_test_e, resize_dim = RESIZE_DIM)\n",
    "X_test_f = get_data(paths_test_f, resize_dim = RESIZE_DIM)\n",
    "X_test_auga = get_data(paths_test_auga, resize_dim = RESIZE_DIM)\n",
    "X_test_augc = get_data(paths_test_augc, resize_dim = RESIZE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pursuant-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = np.concatenate((X_test_a, X_test_b, X_test_c, X_test_d, X_test_e, X_test_f, X_test_auga, X_test_augc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = X_train_all.reshape(X_train_all.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test_all = X_test_all.reshape(X_test_all.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "normal-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all /= 255\n",
    "X_test_all /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generous-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "requested-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asif_\\anaconda3\\envs\\directML\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# my CNN architecture is In -> [[Conv2D->relu]*2 -> BatchNorm -> MaxPool2D -> Dropout]*3 -> Flatten -> Dense -> Activation -> Dropout -> Dense -> Activation -> Out\n",
    "\n",
    "def my_model(img_size = 28,channels = 1):\n",
    "\n",
    "    model = Sequential()\n",
    "    input_shape = (img_size, img_size, channels)\n",
    "    \n",
    "    model.add(Conv2D(32, (5, 5), input_shape = input_shape, activation = 'relu', padding = 'same'))\n",
    "    model.add(Conv2D(32, (5, 5), activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation = 'relu', padding = 'same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation ='relu' , padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attempted-leonard",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57636 samples, validate on 14409 samples\n",
      "Epoch 1/30\n",
      "57636/57636 [==============================] - 250s 4ms/sample - loss: 0.6082 - acc: 0.7872 - val_loss: 0.1754 - val_acc: 0.9435\n",
      "Epoch 2/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.1455 - acc: 0.9573 - val_loss: 0.4433 - val_acc: 0.8816\n",
      "Epoch 3/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.1028 - acc: 0.9702 - val_loss: 0.2063 - val_acc: 0.9398\n",
      "Epoch 4/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0832 - acc: 0.9755 - val_loss: 0.1251 - val_acc: 0.9655\n",
      "Epoch 5/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0686 - acc: 0.9800 - val_loss: 0.1644 - val_acc: 0.9551\n",
      "Epoch 6/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0577 - acc: 0.9835 - val_loss: 0.0847 - val_acc: 0.9774\n",
      "Epoch 7/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0521 - acc: 0.9844 - val_loss: 0.1367 - val_acc: 0.9606\n",
      "Epoch 8/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0487 - acc: 0.9864 - val_loss: 0.1299 - val_acc: 0.9647\n",
      "Epoch 9/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0374 - acc: 0.9891 - val_loss: 0.1035 - val_acc: 0.9743\n",
      "Epoch 10/30\n",
      "57636/57636 [==============================] - 246s 4ms/sample - loss: 0.0340 - acc: 0.9896 - val_loss: 0.1001 - val_acc: 0.9762\n",
      "Epoch 11/30\n",
      "57636/57636 [==============================] - 246s 4ms/sample - loss: 0.0316 - acc: 0.9906 - val_loss: 0.0708 - val_acc: 0.9840\n",
      "Epoch 12/30\n",
      "57636/57636 [==============================] - 246s 4ms/sample - loss: 0.0292 - acc: 0.9914 - val_loss: 0.0859 - val_acc: 0.9828\n",
      "Epoch 13/30\n",
      "57636/57636 [==============================] - 246s 4ms/sample - loss: 0.0261 - acc: 0.9926 - val_loss: 0.0830 - val_acc: 0.9812\n",
      "Epoch 14/30\n",
      "57636/57636 [==============================] - 247s 4ms/sample - loss: 0.0204 - acc: 0.9939 - val_loss: 0.1034 - val_acc: 0.9781\n",
      "Epoch 15/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0228 - acc: 0.9931 - val_loss: 0.0753 - val_acc: 0.9836\n",
      "Epoch 16/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0241 - acc: 0.9931 - val_loss: 0.0971 - val_acc: 0.9819\n",
      "Epoch 17/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0190 - acc: 0.9944 - val_loss: 0.1018 - val_acc: 0.9792\n",
      "Epoch 18/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0182 - acc: 0.9945 - val_loss: 0.0883 - val_acc: 0.9822\n",
      "Epoch 19/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0168 - acc: 0.9953 - val_loss: 0.0789 - val_acc: 0.9838\n",
      "Epoch 20/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0945 - val_acc: 0.9824\n",
      "Epoch 21/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1075 - val_acc: 0.9838\n",
      "Epoch 22/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0149 - acc: 0.9951 - val_loss: 0.1156 - val_acc: 0.9806\n",
      "Epoch 23/30\n",
      "57636/57636 [==============================] - 244s 4ms/sample - loss: 0.0127 - acc: 0.9961 - val_loss: 0.1038 - val_acc: 0.9836\n",
      "Epoch 24/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0117 - acc: 0.9968 - val_loss: 0.1033 - val_acc: 0.9834\n",
      "Epoch 25/30\n",
      "57636/57636 [==============================] - 245s 4ms/sample - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0987 - val_acc: 0.9826\n",
      "Epoch 26/30\n",
      "57636/57636 [==============================] - 248s 4ms/sample - loss: 0.0106 - acc: 0.9971 - val_loss: 0.0847 - val_acc: 0.9837\n",
      "Epoch 27/30\n",
      "57636/57636 [==============================] - 248s 4ms/sample - loss: 0.0120 - acc: 0.9967 - val_loss: 0.1077 - val_acc: 0.9842\n",
      "Epoch 28/30\n",
      "57636/57636 [==============================] - 251s 4ms/sample - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1177 - val_acc: 0.9851\n",
      "Epoch 29/30\n",
      "57636/57636 [==============================] - 253s 4ms/sample - loss: 0.0153 - acc: 0.9959 - val_loss: 0.1108 - val_acc: 0.9722\n",
      "Epoch 30/30\n",
      "57636/57636 [==============================] - 253s 4ms/sample - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0948 - val_acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "path_model = 'output/B_D.h5'\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "model = my_model() \n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(x = X_train, y = y_train, batch_size = 64, epochs=30, verbose=1, validation_data=(X_val,y_val), shuffle=True, callbacks=[ModelCheckpoint(filepath = path_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "immediate-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0948%\n",
      "Test accuracy: 0.9862%\n",
      "Large CNN Error: 1.3811%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_val, y_val, verbose = 0)\n",
    "\n",
    "print('Test loss: %.4f%%' % scores[0])\n",
    "print('Test accuracy: %.4f%%' % scores[1])\n",
    "\n",
    "print(\"Large CNN Error: %.4f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-frederick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
